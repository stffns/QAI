database:
  conversations_path: data/qa_conversations.db
  knowledge_path: data/qa_knowledge.db
  rag_path: data/qa_intelligence_rag.db
  url: sqlite:///./data/qa_intelligence.db
environment:
  data_directory: data
  environment: development
  logs_directory: logs
interface:
  playground:
    enabled: true
    port: 7777
  terminal:
    enable_markdown: true
    show_tool_calls: false
    streaming:
      enabled: false
      show_cursor: true
      cursor_style: "\u26A1"
      typing_delay: 0.02
logging:
  enable_file_logging: true
  level: INFO
  log_file: logs/qa_intelligence.log
model:
  id: gpt-5-mini
  provider: openai
  max_completion_tokens: 200
  stream: true
  show_function_calls: false
  debug: false
  verbose: false
  stream_config:
    enabled: false
    chunk_delay: 0.01
    show_thinking: false
  models:
    nano: gpt-5-nano
    default: gpt-5-mini
    reasoning: gpt-5
  temperatures:
    nano: 1.0
    default: 1.0
    reasoning: 0.3
  system_instructions: 'You are QA Intelligence, a helpful assistant for QA testing and analysis.

    STRICT RESPONSE RULES:
    1. NEVER start responses with function names like "get_qa_apps()", "perf_get_status()", etc.
    2. NEVER mention execution times like "completed in 0.0091s"
    3. NEVER show tool names, function calls, or technical execution details
    4. Respond as if you naturally know the information

    Response format:
    - Start directly with the answer: "Available applications:", "The test...", "Found..."
    - Be conversational and helpful
    - Provide clear, direct information
    - Ask follow-up questions when appropriate

    BAD examples:
    - "get_qa_apps() completed in 0.0091s. Available applications..."
    - "I need to check the database..."
    - "Let me run a query..."

    GOOD examples:
    - "Available applications: EVA and ONEAPP"
    - "The latest test completed successfully"
    - "Found 3 endpoints ready for testing"

    Always respond naturally as a knowledgeable QA expert.
    '
tools:
  enabled: true
  show_results: false
  show_execution_time: false
  debug: false
  tools:
  - enabled: false
    name: web_search
  - enabled: false
    name: python_execution
  - enabled: false
    name: file_operations
  - enabled: true
    name: qa_database_stats
  - enabled: true
    name: qa_apps
  - enabled: true
    name: qa_countries
  - enabled: true
    name: qa_mappings
  - enabled: true
    name: qa_search
  - enabled: true
    name: sql_execute_query
  - enabled: true
    name: sql_analyze_table
  - enabled: true
    name: sql_explore_database
  - enabled: true
    name: sql_qa_analytics
  - enabled: true
    name: api_test_endpoint
  - enabled: true
    name: api_health_check
  - enabled: true
    name: perf_submit_run
  - enabled: true
    name: perf_get_status
  - enabled: true
    name: perf_list_recent
  - enabled: true
    name: perf_discover_endpoints
  - enabled: true
    name: perf_run_test
  - enabled: true
    name: perf_get_metrics
reasoning:
  enabled: true
  type: agent
  triggers:
  - explain in detail
  - analyze
  - complex reasoning
  - step by step
  - comprehensive
  - how does
  - why does
  - compare
  - pros and cons
  auto_reasoning: false
  reasoning_model:
    id: gpt-5
    temperature: 0.3
    max_completion_tokens: 1500
  nano_triggers:
  - hello
  - hi
  - thanks
  - ok
  - 'yes'
  - bye
  - thank you
  - 'no'
  - good
  - bye
rag:
  database_path: data/qa_intelligence_rag.db
  version: pure_v2
  migration_date: '20250908_111143'
  collections_enabled: true
  default_embedding_model: text-embedding-3-small
  analytics_enabled: true
  cache_enabled: true

websocket:
  show_tool_calls: false
  show_tool_results: false
  markdown: true
  stream: true
  brief_responses: true
